# PetLovers
ğŸš€ Apresento um projeto simulando uma colaboraÃ§Ã£o com a PetLovers, um e-commerce (fictÃ­cio) especializado em produtos para cÃ£es.
A PetLovers enfrentava um desafio comum em empresas digitais: entender, de forma estruturada, como seus clientes percebem os produtos. Embora algumas categorias registrassem boas vendas, a equipe ainda nÃ£o compreendia claramente os fatores que impulsionavam esse desempenho: preÃ§o, marca, qualidade percebida ou outros elementos?
ğŸ§© O principal problema identificado foi a falta de visibilidade consolidada sobre a opiniÃ£o dos consumidores, o que limitava a atuaÃ§Ã£o estratÃ©gica da equipe de marketing.
ğŸ’¡ Neste projeto, construÃ­ um pipeline de dados completo â€” da extraÃ§Ã£o (via web scraping) atÃ© o tratamento, enriquecimento e modelagem â€” com foco em transformar dados dispersos (como comentÃ¡rios, avaliaÃ§Ãµes e caracterÃ­sticas dos produtos) em insights acionÃ¡veis.
A entrega final serÃ¡ um dashboard interativo, voltado para a equipe de marketing. Esse dashboard serÃ¡ uma ferramenta estratÃ©gica essencial para a equipe de marketing, transformando dados dispersos em decisÃµes mais inteligentes e eficazes permitindo:
Identificar produtos com alto potencial de destaque;
Detectar padrÃµes de satisfaÃ§Ã£o e insatisfaÃ§Ã£o por marca e categoria;
Relacionar percepÃ§Ã£o do cliente com preÃ§o e volume de avaliaÃ§Ãµes.
Entre outros.
ğŸ” Como transformar dados soltos em inteligÃªncia para decisÃµes de marketing?

ğŸ“Œ 1. Coleta de Dados
 Utilizei tÃ©cnicas de web scraping com Selenium, Requests e BeautifulSoup para extrair informaÃ§Ãµes de produtos voltados para cÃ£es no site da PetLovers â€” incluindo preÃ§os, avaliaÃ§Ãµes, comentÃ¡rios e descriÃ§Ãµes.
ğŸ§¹ 2. Processamento e Limpeza
 Com PySpark, realizei a padronizaÃ§Ã£o dos dados e tratamento de inconsistÃªncias. Essa etapa foi crucial para garantir a integridade da anÃ¡lise.
ğŸ”¬ 3. Enriquecimento de Dados
 Criei novas variÃ¡veis derivadas e features Ãºteis para anÃ¡lise â€” como mÃ©dia ponderada de avaliaÃ§Ãµes e classificaÃ§Ã£o de produtos por desempenho â€” documentadas em um book de variÃ¡veis.
ğŸ“¦ 4. Armazenamento Final
 Adotei uma estrutura em camadas para organizaÃ§Ã£o dos dados:
Raw (dados brutos),
Processed (dados limpos e organizados),
Curated (dados prontos para anÃ¡lise).
ğŸ“Š 5. VisualizaÃ§Ã£o e AnÃ¡lise
 O pipeline termina em um dashboard interativo no Power BI, desenhado para oferecer Ã  equipe de marketing uma visÃ£o estratÃ©gica com insights sobre:
Produtos com alto potencial de destaque;
Marcas e categorias com maior (ou menor) satisfaÃ§Ã£o;
A relaÃ§Ã£o entre preÃ§o, avaliaÃ§Ãµes e percepÃ§Ã£o dos clientes.
Essa estrutura permite Ã  PetLovers transformar dados desconectados em aÃ§Ãµes orientadas por evidÃªncias.
ğŸ” Como coletei os dados para transformar opiniÃµes soltas em inteligÃªncia de marketing?
O desafio era obter dados detalhados de diversos produtos â€“ incluindo preÃ§os, marcas, avaliaÃ§Ãµes, comentÃ¡rios e percepÃ§Ãµes especÃ­ficas dos consumidores â€“ de forma automatizada, confiÃ¡vel e escalÃ¡vel.
ğŸ’» Para isso, construÃ­ um processo robusto de web scraping, utilizando:
ğŸ“Œ Selenium + BeautifulSoup + Requests
Combinando essas trÃªs ferramentas, consegui navegar por mÃºltiplas pÃ¡ginas do site, simular interaÃ§Ãµes (como rolagem e cliques), capturar dados estruturados e nÃ£o estruturados e tratar variaÃ§Ãµes na resposta das pÃ¡ginas.
ğŸ“‚ O scraping resultou em quatro conjuntos de dados principais:
InformaÃ§Ãµes gerais dos produtos (nome, categoria, marca, preÃ§o, nota mÃ©dia, etc.).
ComentÃ¡rios dos clientes, capturados atÃ© mesmo dentro de modais e iframes dinÃ¢micos.
AvaliaÃ§Ã£o por caracterÃ­sticas (ex: durabilidade, custo-benefÃ­cio).
URLs que nÃ£o responderam â€” registradas para controle de qualidade e tentativa futura.
âš ï¸ AlÃ©m disso, adicionei controle de fluxo para evitar bloqueios por excesso de requisiÃ§Ãµes, com pausas estratÃ©gicas a cada 100 produtos extraÃ­dos.
Essa etapa Ã© fundamental: sem dados confiÃ¡veis, nÃ£o hÃ¡ anÃ¡lise relevante. Todo o pipeline posterior (limpeza, enriquecimento, visualizaÃ§Ã£o) depende de uma coleta bem feita â€” e, nesse caso, o foco foi garantir profundidade, diversidade e precisÃ£o dos dados extraÃ­dos.
